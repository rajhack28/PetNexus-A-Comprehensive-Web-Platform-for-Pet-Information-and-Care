{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajhack28/PetNexus-A-Comprehensive-Web-Platform-for-Pet-Information-and-Care/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7_fKxPBcZiB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout, BatchNormalization, TimeDistributed, Reshape\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NYmFDPYVWXm",
        "outputId": "f601e7bc-7786-46ab-a1ca-617d422f3157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11469 images belonging to 14 classes.\n",
            "Found 2865 images belonging to 14 classes.\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 39/359\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54:37\u001b[0m 21s/step - accuracy: 0.1293 - loss: 2.9147"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, LSTM, Reshape, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image dimensions\n",
        "img_width, img_height = 224, 224  # Adjusted to match pre-trained models\n",
        "num_classes = 14  # 14 hand gestures\n",
        "\n",
        "# Use VGG16 as a feature extractor\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "# Uncomment below to use ResNet50 instead\n",
        "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Freeze the base model layers to retain pre-trained features\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    base_model,  # Use pre-trained base model\n",
        "    Flatten(),   # Flatten to transition to dense layers\n",
        "    Reshape((1, -1)),  # Reshape for LSTM compatibility\n",
        "\n",
        "    # LSTM layer for sequence learning\n",
        "    LSTM(128, return_sequences=False),  # Increased LSTM units\n",
        "\n",
        "    # Fully connected layers\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),  # Dropout for regularization\n",
        "\n",
        "    # Output layer for 14 classes\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),  # Lower learning rate\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Load training and validation data\n",
        "batch_size = 32\n",
        "dataset_path = '/content/drive/My Drive/HG14-Hand Gesture'\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_steps=len(val_data)\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aiKewQzZxwPNwqnR_PFVAkh6C1YP-a0k",
      "authorship_tag": "ABX9TyNfJxuHzhxWNukg+02e0n7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}